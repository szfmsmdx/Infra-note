> 参考 [长度外推综述](https://blog.csdn.net/v_JULY_v/article/details/135072211)、[旋转式位置编码 (RoPE) 知识总结](https://zhuanlan.zhihu.com/p/662790439) 

# 直接外推

首先我们定义长度外推这个问题：长度外推是指模型在未经过长序列训练的情况下，能够有效理解和生成超出其训练最大长度的文本。

当 RoPE 讨论了远程衰减性后，我们进一步讨论不同 dim 的影响 $\theta_i = 10000^{-2i/d}$ 观察公式，我们知道：
- 当 i = 0 时， $\theta_i=1$ ，此时周期为 $2\pi / \theta_0=2\pi$ ，也就是说，在 i=0 这个dim，经过 6 个预训练序列长度，q k的位置编码就可以转一圈
- 当 i = d、2 时，$\theta_i=1e^{-4}$ 此时周期为 $T=1e^4 * 2\pi$ 也就是大概 62,832 才能转一圈，此时预训练的长度一般是 2048，并不能很好保证模型在推理时也能够处理很后面的角度，效果一般不好

如果我们不管，还是采用 RoPE 硬上，那这个就叫**直接外推**

那么如何解决这个问题呢？常规的思路肯定还是把推理的长序列给映射会我们训练的长度，一个简单的想法就是：线性内插

# 线性内插 Position Interpolation (PI)
简单来说，我们可以把原来的 $\theta_i=10000^{-2i/d}\cdot k^{-1}$ ，其中 k 是推理时的最大长度，这也就是放缩了原始的位置增速，也就是 $p\theta=\frac p\alpha \theta$ ，其中 p 是位置，α 就是那个 k 
效果：
- 无额外训练的情况下，线性内插比直接外推效果差
- 有增量训练可以达到和原本效果相近

# NTK-aware Scaled RoPE
此外还有人想到，既然 RoPE 在小序列经过训练，那么推理时的靠前序列为什么要动呢？我们直接把后面比较长的部分插值不就好了，那么也就是说：
- 在 i 比较小的时候，几乎等价于直接外推
- 在 i 比较大的时候，给缩放回原训练长度
研究者们提出了一个公式： $\theta_i=(10000\cdot k)^{-2i/d}$ ，这里$k=\frac{L_{训练}}{L_{推理}}$ ，恰好满足：
- 当 i = 0时，$\theta_i=1$ 无影响
- 当 i = d/2 时，$\theta_i=10000 k$ ，给缩放回训练长度了
简单来说，NTK 做的是直接外推和线性内插的光滑版

效果：
- 无增量训练情况下仅 5% 左右的性能下降

## Dynamic Scaling
Dynamic Scaling 进一步动态调整 $s$ 以适配不同上下文长度：
$g(m) = m$ 、$h(\theta_d) = b^{-2d/|D|} \cdot (as - a + 1)^{-2d/|D|}$ 或者采用指数形式：$h(\theta_d) = b^{-2i/d} \cdot \exp\left(-a \cdot (2i + 1)^b\right)$ 

效果：
- 差不多有 1%~2%的性能提升

## NTK-by-parts Interpolation
公式太长就不放了，简单来说，就是把推理上下文分成三个区间：
- 短波长就不动了，保留原始 RoPE 信息
- 中波长 ramp 函数平滑过渡
- 长波长用线性插值


# ReRoPE
ReRope 的想法是：之前包括 NTK、线性内插的问题都是，他们直接控制的是位置编码，也就是 $q_m=q \cdot R_m$ 的这个 $R_m$ ，但是 Attention 依赖相对位置呀，那我为什么要管绝对位置是不是超出了训练范围呢？在标准 RoPE / NTK / 线性插值 里：
- 一旦 token 位置本身 > $L_{\text{train}}$  
- 即便两个 token 离得很近
- 相位也已经进入“外推区间”

也就是说，相对位置不变的时候，我们就用原始的 RoPE
定义： $$ \Delta = p' - p $$ ReRoPE 用的是： $$ \boxed{ \text{angle}_i^{\text{ReRoPE}}(\Delta) = \theta_i \cdot \begin{cases} \Delta, & |\Delta| \leq L_{\text{train}} \\ L_{\text{train}} + \dfrac{\Delta - L_{\text{train}}}{\alpha}, & \Delta > L_{\text{train}} \\ -L_{\text{train}} + \dfrac{\Delta + L_{\text{train}}}{\alpha}, & \Delta < -L_{\text{train}} \end{cases} } $$

或者说，我们不考虑这个 α 缩放，我们直接用类似 ReLU 的思想给他截断，其实也没问题，采用 LeaklyReLU，也没问题，效果：
- ReRoPE 几乎只有 1% 的性能下降，且可以处理任意长度

但是这种方案有一个问题：
- 推理成本会增加
在前面的方案，我们处理这个位置编码，处理完可以继续带入 Attention 计算，但是这里要先算相对位置，Attention 中出现了分段，推理成本会增加一些

这里苏建林想到一个方案：
在预训练的时候采用 Leakly RoPE，在推理时采用原始的 RoPE 直接外推。经过实验, 这样做性能下降也是在 1% 以内。如果你有资源重新训练大模型, 这会是一个很好的方案。

# Yarn
Yarn = NTK-aware + NTK-by-parts + Dynamic NTK
他也是直接解决 Attention 点积的思路：由于线性内插会改变旋转向量转动的幅度，原来距离较远的q,k点积由于旋转幅度变小，他们的点积结果会增大，进而导致Softmax操作过于“锐化”，使得注意力分布集中于少数位置，削弱模型对全局上下文的关注能力。
Yarn在 NTK-by-parts 基础上，引入注意力温度因子  来调整注意力分布：
$$ \text{softmax}\left( \frac{q_m^T k_n}{t \sqrt{|D|}} \right), \quad \sqrt{\frac{1}{t}} = 0.1 \ln(s) + 1 $$